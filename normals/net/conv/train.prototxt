name: "PixelNet"

# This example normalizes the surface normal before doing regresssion
# To use this .prototxt file for training, "rand_selection" param in "RandCatConv"
# layer is set to 'true', and for evaluation/deployment - it is 
# set to 'false'. This switch ensures the random selection of pixels
# at training time, and considering all the pixels at deployment.

# include the data layer 
# data0 -- for image source
# data1 -- for the corresponding surface normal values.
# data2 -- for valid source pixels


layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data0"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2_re"
}

####
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2_re"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}

layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2_re"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2_re"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}

layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}

layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3_re"
}

####
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3_re"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}

layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3_re"
}

##
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3_re"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}

layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}

layer {
  bottom: "conv5_3"
  top: "conv5_3_re"
  name: "relu5_3"
  type: "ReLU"
}

layer {
  bottom: "conv5_3_re"
  top: "pool5"
  name: "pool5"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {
  bottom: "pool5"
  top: "fc6_conv"
  name: "fc6_conv"
  type: "Convolution"
  convolution_param {
        kernel_size: 7
        num_output: 4096
  }
}

layer {
  bottom: "fc6_conv"
  top: "fc6_conv"
  name: "relu6"
  type: "ReLU"
}

layer {
  bottom: "fc6_conv"
  top: "fc6_conv"
  name: "drop6"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  bottom: "fc6_conv"
  top: "fc7_conv"
  name: "fc7_conv"
  type: "Convolution"
  convolution_param {
        kernel_size: 1
        num_output: 4096
  }
}

layer {
  bottom: "fc7_conv"
  top: "fc7_conv"
  name: "relu7"
  type: "ReLU"
}

layer {
  bottom: "fc7_conv"
  top: "fc7_conv"
  name: "drop7"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.5
  }
}


###
layer {
    name: "rand_concat_conv"
    type: "RandCatConv"
    bottom: "conv1_2"
    bottom: "conv2_2"
    bottom: "conv3_3"
    bottom: "conv4_3"
    bottom: "conv5_3"
    bottom: "fc7_conv"
    bottom: "data2"
    bottom: "data1"
    top: "fc5"
    top: "pixel_sn"
    rand_cat_conv_param{
        num_output: 1500
        rand_selection: true
	pooling_factor: 1
	pooling_factor: 2
	pooling_factor: 4
	pooling_factor: 8
	pooling_factor: 16
	pooling_factor: 224
    }
}


## -- train fully connected layer on top of it --
layer {
  name: "fc6_hcol"
  type: "InnerProduct"
  bottom: "fc5"
  top: "fc6_hcol"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.0005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6_hcol"
  type: "ReLU"
  bottom: "fc6_hcol"
  top: "fc6_hcol"
}
layer {
  name: "drop6_hcol"
  type: "Dropout"
  bottom: "fc6_hcol"
  top: "fc6_hcol"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  name: "fc7_hcol"
  type: "InnerProduct"
  bottom: "fc6_hcol"
  top: "fc7_hcol"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.0005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7_hcol"
  type: "ReLU"
  bottom: "fc7_hcol"
  top: "fc7_hcol"
}
layer {
  name: "drop7_hcol"
  type: "Dropout"
  bottom: "fc7_hcol"
  top: "fc7_hcol"
  dropout_param {
    dropout_ratio: 0.5
  }
}


layer {
  name: "fc8_hcol"
  type: "InnerProduct"
  bottom: "fc7_hcol"
  top: "fc8_hcol"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.0005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}

layer {
  name: "fc8_hcol_norm"
  type: "Normalize"
  bottom: "fc8_hcol"
  top: "fc8_norm"
  norm_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    across_spatial: false
    channel_shared: false
    fix_scale: true
  }
}

##loss-layer --
layer {
        type: "EuclideanLoss"
        name: "loss_sn"
        bottom: "fc8_norm"
        bottom: "pixel_sn"
}
